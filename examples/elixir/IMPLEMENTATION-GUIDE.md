> ‚ö†Ô∏è **This is an example implementation guide for Elixir/BEAM stack.**  
> **For general principles, see [IMPLEMENTATION-GUIDELINES.md](../../IMPLEMENTATION-GUIDELINES.md) in the root.**

---

# Elixir Implementation Guide
## Optimizing copilot-instructions.md for the Zero-Hallucination Protocol

This guide shows how the general implementation principles from the Zero-Hallucination Protocol are applied to a **real Elixir/Phoenix project** using GitHub Copilot.

**Context:** This implementation manages a ~1000-line `copilot-instructions.md` file for an Elixir/BEAM project, optimized for Claude Sonnet 3.5 and GPT-4 with 200K context windows.

**Purpose:** Serve as a **concrete template** for others implementing the protocol in their own stacks.

---

## Principios de Dise√±o

### 1. LLM-First Optimization

El protocolo est√° escrito para ser parseado por modelos de lenguaje, NO para legibilidad humana.

**Formato Imperativo:**
```yaml
# ‚úÖ CORRECTO (imperativo, estructurado)
WHEN_IN_DOUBT:
  STOP ‚Üí CLARIFY ‚Üí VERIFY ‚Üí EXECUTE

# ‚ùå INCORRECTO (narrativo, explicativo)
When you're not sure what to do, you should stop and clarify with the user,
then verify your understanding before executing the task.
```

**Keywords en UPPERCASE:**
```yaml
# ‚úÖ CORRECTO
IF MODE == "PIPELINE" AND LINES > 1500:
  CRITICAL_ERROR

# ‚ùå INCORRECTO
if mode == "pipeline" and lines > 1500:
  critical error
```

**Operadores L√≥gicos Expl√≠citos:**
```yaml
# ‚úÖ CORRECTO
1_EXECUTION_CONTEXT ‚Üí 2_SOURCE_CODE ‚Üí 3_SPECIFICATIONS ‚Üí 4_AI_KNOWLEDGE

# ‚ùå INCORRECTO
Execution context, then source code, then specifications, then AI knowledge
```

**Sin Decorativos:**
- ‚ùå NO emojis: `‚õî **CRITICAL**` ‚Üí ‚úÖ `**CRITICAL**`
- ‚ùå NO flechas decorativas: `‚Üí` (solo en operadores l√≥gicos)
- ‚ùå NO bullets decorativos: `-`, `‚Ä¢`, `‚ñ∏`

---

### 2. Lost-in-Middle Mitigation

LLMs tienen degradaci√≥n de atenci√≥n en zona media de documentos largos.

**Zonas de Atenci√≥n:**
```
L√≠neas 1-200:    HIGH attention (inicio + recencia)
L√≠neas 200-700:  LOW attention  (zona media = Lost-in-Middle)
L√≠neas 700-1000: MEDIUM attention (recencia pero fatiga)
```

**Regla Cr√≠tica:**
Secciones que determinan flujo de ejecuci√≥n DEBEN estar en Top 200 l√≠neas.

**Secciones Cr√≠ticas (No Mover):**
- `EXECUTION_ORDER` (L42, LAYER 0)
- `CONTEXT_VARS` (L98, LAYER 0)
- `HIERARCHY_OF_TRUTH` (L114, LAYER 0)
- `COGNITIVE_SMELLS_DETECTOR` (L145, LAYER 1)

---

### 3. Token Budget

**Target:** <10,000 tokens (5% de 200K context)  

**Trade-off Justificado:**
- ‚úÖ +tokens SI reduce Lost-in-Middle risk
- ‚úÖ +tokens SI mejora parsing LLM (separadores, estructura)
- ‚ùå +tokens por contenido duplicado
- ‚ùå +tokens por decorativos (emojis, narrativa)

---

### 4. Layered Architecture

Protocolo organizado en 5 capas con prop√≥sitos espec√≠ficos:

```
LAYER 0 (L38-140):  ABSOLUTE PRIORITIES & EXECUTION ROUTING
                    ‚Ü≥ EXECUTION_ORDER, CONTEXT_VARS, HIERARCHY_OF_TRUTH

LAYER 1 (L128-252): COGNITIVE FIREWALL
                    ‚Ü≥ COGNITIVE_SMELLS_DETECTOR

LAYER 2 (L253-614): SAFETY GATES
                    ‚Ü≥ DECISION_ALGORITHM, DUPLICATION_CHECK, VERIFICATION, MODE_SELECTION

LAYER 3 (L615-779): EXECUTION MECHANICS
                    ‚Ü≥ PREFLIGHT, PHASE_EXECUTION, ANTIPATTERN, CLARIFICATION

LAYER 4 (L780-END): OUTPUT FORMAT & TOOL REFERENCE
                    ‚Ü≥ RESPONSE_PROTOCOL, TOOL_USAGE, COGNITIVE_HOOK
```

**Separadores Visuales:**
```markdown
‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
# LAYER N: NOMBRE
# Descripci√≥n prop√≥sito (imperativo)
‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
```

**79 caracteres** de separador (‚ïê‚ïê‚ïê) = se√±al visual fuerte para LLMs.

---

## Checklist Pre-Modificaci√≥n

Antes de modificar `copilot-instructions.md`:

### 1. Formato y Estilo

- [ ] **Imperativo:** Keywords UPPERCASE, IF/THEN/ELSE, operadores ‚Üí expl√≠citos
- [ ] **Sin decorativos:** Emojis, flechas narrativas, bullets decorativos eliminados
- [ ] **Estructura:** Bloques YAML con indentaci√≥n consistente (2 espacios)
- [ ] **Prefijos num√©ricos:** 1_EXECUTION_CONTEXT, STEP_1, etc.

### 2. Posici√≥n y Estructura

- [ ] **Secciones cr√≠ticas:** Permanecen en Top 200 l√≠neas (verificar con script)
- [ ] **LAYER correcto:** Nueva secci√≥n va en capa apropiada (0-4)
- [ ] **Separadores:** Headers de LAYER con ‚ïê‚ïê‚ïê de 79 caracteres

### 3. Contenido

- [ ] **Duplicaci√≥n:** Buscar contenido similar (grep, semantic search)
- [ ] **Referencias:** Verificar funciones/m√≥dulos existen (no asumir)
- [ ] **Ejemplos:** Concretos, no gen√©ricos (contexto Elixir/BEAM)

### 4. Impacto

- [ ] **Tokens:** Calcular, mantener <10K total
- [ ] **Lost-in-Middle:** Si mueves secciones, recalcular riesgo
- [ ] **Trade-off:** Justificar +tokens con -riesgo o +parsing efficiency

---

## Checklist Post-Modificaci√≥n

Despu√©s de modificar `copilot-instructions.md`:

### 1. Validaci√≥n Estructural

### 2. M√©tricas de Impacto

### 3. Posiciones Cr√≠ticas

### 4. CHANGELOG

- [ ] **Actualizar:** `.github/CHANGELOG-PROTOCOL.md`
- [ ] **Formato:** Added/Changed/Removed/Performance/Why
- [ ] **M√©tricas:** Incluir l√≠neas, tokens, delta, posiciones before/after
- [ ] **Rationale:** Explicar POR QU√â se hizo el cambio (no solo QU√â)

Ejemplo entrada CHANGELOG:
```markdown
## [3.X.0] - YYYY-MM-DD

### Changed
- Secci√≥n X movida de LY ‚Üí LZ (rationale: Lost-in-Middle mitigation)

### Performance
- L√≠neas: A ‚Üí B (ŒîC)
- Tokens: X ‚Üí Y (ŒîZ, +N%)
- Lost-in-Middle: Risk assessment

### Why
Problema identificado: [descripci√≥n]
Soluci√≥n implementada: [pasos]
Resultado: [m√©tricas + impacto]
```

---

## Decisiones Arquitect√≥nicas (No Cambiar Sin Discusi√≥n)

### 1. Layered Architecture (5 capas)

**Establecida:** v3.7.0  
**Rationale:** Mitigaci√≥n Lost-in-Middle, organizaci√≥n clara por prop√≥sito

**NO cambiar sin:**
- An√°lisis de impacto en posiciones cr√≠ticas
- Rec√°lculo Lost-in-Middle risk
- Discusi√≥n en issue/PR

### 2. ABSOLUTE_PRIORITIES en L6

**Establecida:** v3.7.0 (FASE 1)  
**Rationale:** Anchoring strategy - LLM lee primero (alta atenci√≥n) y √∫ltimo (recencia)

**Contenido:**
- EXECUTION_HIERARCHY (5 reglas)
- WHEN_IN_DOUBT (flujo STOP ‚Üí CLARIFY ‚Üí VERIFY ‚Üí EXECUTE)
- SEVERITY_OVERRIDES
- HIERARCHY_OF_TRUTH
- MANDATORY_OUTPUT

**NO mover, NO duplicar.**

### 3. Secciones Cr√≠ticas en LAYER 0-1

**Establecida:** v3.7.0 (FASE 2)  
**Rationale:** Top 200 l√≠neas = zona alta atenci√≥n LLM

**Secciones:**
- EXECUTION_ORDER (L42)
- CONTEXT_VARS (L98)
- HIERARCHY_OF_TRUTH (L114)
- COGNITIVE_SMELLS_DETECTOR (L145)

**NO mover fuera de Top 200 sin justificaci√≥n cr√≠tica.**

### 4. No Extraer Secciones Cr√≠ticas a Skills

**Decidido:** v3.7.0 (an√°lisis skills)  
**Rationale:** Skills no garantizan carga 100%, secciones cr√≠ticas deben estar en protocolo principal

**Secciones NO extra√≠bles:**
- RESPONSE_PROTOCOL (validaci√≥n formato obligatoria)
- MODE_SELECTION_EXPLICIT (decisi√≥n LEGACY vs PIPELINE cr√≠tica)
- EXECUTION_ORDER (flujo fundamental)
- DUPLICATION_CHECK (prevenci√≥n bugs cr√≠ticos)

**Secciones extra√≠bles (bajo riesgo):**
- VERIFICATION_WHEN_CHALLENGED (caso uso espec√≠fico)
- Descripciones largas de COGNITIVE_SMELLS (mantener tabla en protocolo)

### 5. Formato Sin Decorativos

**Establecida:** v3.7.0 (FASE 1 + eliminaci√≥n emojis)  
**Rationale:** Emojis/decorativos NO aportan parsing value, agregan tokens innecesarios

**Eliminados:**
- Emojis (‚õîüìÅüìèüöß‚ö†Ô∏è‚ùå‚úÖ)
- Flechas decorativas (‚Üí solo en operadores l√≥gicos)
- Bullets decorativos

**Mantenidos:**
- Negrita `**KEYWORD**` (jerarqu√≠a visual)
- Bloques c√≥digo ` ```yaml `
- Separadores `‚ïê‚ïê‚ïê` (se√±al visual fuerte)

---

## Cu√°ndo NO Optimizar

**NO optimizar si:**

1. **Token count <5% context:** Ya estamos en 4.6% (excelente)
2. **Lost-in-Middle VERY LOW:** -65% mitigado es suficiente
3. **Micro-optimizaciones <100 tokens:** ROI bajo, esfuerzo > beneficio
4. **Funcionalidad estable:** Protocolo funciona correctamente

### Se√±ales de Over-Optimization

- Extraer secciones a skills por ahorrar 50 tokens
- Comprimir c√≥digo legible por reducir 2 l√≠neas
- Abreviar keywords (EXEC en lugar de EXECUTION_ORDER)
- Eliminar ejemplos concretos por reducir tama√±o

**Regla:** Si cambio reduce claridad > ahorro tokens = NO HACER

---

## Recursos Relacionados

- **CHANGELOG:** [CHANGELOG-PROTOCOL.md](CHANGELOG-PROTOCOL.md) - Historial de cambios y rationale
- **Skills:** [skills/README.md](skills/README.md) - Gu√≠a de skills disponibles
- **Protocolo:** [copilot-instructions.md](copilot-instructions.md) - Protocolo actual

---

## Preguntas Frecuentes

### ¬øCu√°ndo crear una nueva LAYER?

**Nunca.** Las 5 capas actuales cubren todos los casos:
- LAYER 0: Prioridades y routing
- LAYER 1: Detecci√≥n de problemas
- LAYER 2: Prevenci√≥n de problemas
- LAYER 3: Mec√°nicas de ejecuci√≥n
- LAYER 4: Formato output y herramientas

Si nueva secci√≥n no encaja, repensar prop√≥sito de la secci√≥n.

### ¬øPuedo agregar ejemplos largos?

Evaluar trade-off:
- ‚úÖ Ejemplo concreto Elixir/BEAM que aclara patr√≥n complejo: OK
- ‚ùå Ejemplo gen√©rico que duplica explicaci√≥n: NO

Regla: 1 ejemplo bueno > 3 ejemplos mediocres
### ¬øPor qu√© el RESPONSE_PROTOCOL es tan largo?

**Respuesta corta:** La verbosidad es intencional.

**Respuesta larga:**

El protocolo de respuesta puede parecer excesivamente detallado:
- Secci√≥n de razonamiento
- Lista de verificaciones
- Asunciones expl√≠citas
- Pr√≥ximos pasos
- Cognitive Hook

**NO LO ACORTES.** Esa verbosidad cumple prop√≥sitos cr√≠ticos:

1. **Trazabilidad:** Si el protocolo falla, puedes ver D√ìNDE
   - ¬øSe salt√≥ la verificaci√≥n?
   - ¬øAsumi√≥ algo sin confirmarlo?
   - ¬øEjecutar sin pre-flight?

2. **Mejora Continua:** Los logs verbosos revelan patrones
   - Qu√© validaciones se omiten frecuentemente
   - Qu√© cognitive smells son m√°s comunes
   - D√≥nde el protocolo necesita refuerzo

3. **Accountability:** El AI debe mostrar su trabajo
   - No puede generar c√≥digo "m√°gico" sin explicar
   - Asunciones impl√≠citas se vuelven expl√≠citas
   - Decisiones arquitect√≥nicas son justificadas

4. **Forcing Function:** La estructura obliga disciplina
   - No puede saltarse la reflexi√≥n si el formato la requiere
   - No puede ignorar cognitive smells si debe documentarlos

**Trade-off:**
- Respuestas cortas: R√°pidas pero opacas (no puedes debuggear fallos)
- Respuestas verbosas: M√°s lentas pero transparentes (puedes mejorar protocolo)

**Elecci√≥n:** Optimizamos para confiabilidad a largo plazo, no conveniencia a corto plazo.

**Ejemplo Real:**

Sin verbosidad:
```
‚úì Archivo modificado.
```
‚Ü≥ Si falla despu√©s, no sabes qu√© valid√≥, qu√© asumi√≥, qu√© ignor√≥.

Con verbosidad:
```
PRE_FLIGHT_CHECK:
  ‚úì Verified function exists via grep
  ‚úì Read source code (lines 45-78)
  ‚úì Confirmed no side effects
  ‚úì Identified similar pattern in other_module.ex

CHANGES:
  - Modified handle_call/3 clause
  - Preserved existing error handling
  
ASSUMPTIONS:
  - Assuming GenServer is already started
  - Assuming state structure remains {:ok, map()}

VERIFICATION:
  - Run: mix test test/my_module_test.exs
  - Check: No compiler warnings
```
‚Ü≥ Si falla, sabes exactamente qu√© se verific√≥ y qu√© se asumi√≥.

**Regla:** Si consideras acortar RESPONSE_PROTOCOL, pregunta: "¬øEsto me ayudar√° a debuggear fallos del protocolo?" Si no, NO LO ACORTES.
### ¬øDebo actualizar CHANGELOG siempre?

S√ç, para cualquier cambio que:
- Modifica estructura (secciones, LAYERS)
- Afecta tokens >100
- Cambia decisiones arquitect√≥nicas
- Agrega/elimina secciones

NO para:
- Typos menores
- Ajustes de formato sin impacto sem√°ntico

### ¬øQu√© hacer si CHANGELOG crece mucho?

Mantener √∫ltimas 5 versiones detalladas, archivar antiguas en `CHANGELOG-PROTOCOL-ARCHIVE.md`.

---

## Adapting This Approach to Your Stack

This guide is **Elixir-specific**, but the principles are **universal**.

### What to Keep (Stack-Agnostic)

- LLM-First optimization (imperative format, UPPERCASE keywords)
- Lost-in-Middle mitigation (critical sections in top 200 lines)
- Token budget management (<10% context window)
- Layered architecture (organize by purpose)
- Pre-flight validation checklists
- Cognitive smell detection

### What to Adapt (Stack-Specific)

1. **Tool names**: `mix`, `grep`, `iex` ‚Üí your stack's equivalents
2. **File patterns**: `*.ex`, `mix.exs` ‚Üí your extensions/configs
3. **Language idioms**: `defmodule`, `@spec` ‚Üí your syntax
4. **Example code**: Elixir patterns ‚Üí your language patterns
5. **Layer count**: 5 layers work for this project; yours may need 3 or 7

### Questions to Ask for Your Stack

- **What are my critical sections?** (Mode selection? Type validation?)
- **What tools verify code?** (LSP? Compiler? Linters?)
- **What's my token budget?** (Based on your typical file sizes)
- **What cognitive smells are common?** (In your team's codebase)
- **What's my context window?** (8K? 32K? 200K?)

### Starting Point

1. Read [IMPLEMENTATION-GUIDELINES.md](../../IMPLEMENTATION-GUIDELINES.md) (general principles)
2. Clone this structure as template
3. Replace Elixir-specific content with your stack
4. Test with real tasks from your codebase
5. Measure and iterate (tokens, Lost-in-Middle risk, effectiveness)

**Remember:** This guide shows **one way** to implement the protocol. Your stack may need different optimizations, but the **core principles remain the same**.

---

**√öltima actualizaci√≥n:** Enero 16, 2026  
**Versi√≥n protocolo:** v3.7.0  
**Stack:** Elixir/Phoenix/BEAM
